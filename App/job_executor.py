import os
import time
import subprocess
import re
from pathlib import Path

def wrap_data_analysis_code(code, dataset_path, timestamp):
    """
    Create a simple wrapper for the LLM-generated analysis code.
    """
    wrapped_code = f"""import time
import warnings
import sys
import os
import glob

# Suppress warnings for cleaner output
warnings.filterwarnings("ignore")

# Change to the output directory where the script runs
os.chdir('/home/vpatel69/R1/App/output/')

print("="*50)
print("DATA ANALYSIS EXECUTION")
print("="*50)
print(f"Execution start time: {{time.strftime('%Y-%m-%d %H:%M:%S')}}")
print(f"Working directory: {{os.getcwd()}}")
print(f"Job timestamp: {timestamp}")

# Start timing
start_time = time.perf_counter()

# Execute the LLM-generated analysis code
{code}

# Post-process: Rename any PNG files generated by this job to include timestamp
png_files = glob.glob('*.png')
if png_files:
    print(f"\\nRenaming {{len(png_files)}} PNG files with job timestamp...")
    for png_file in png_files:
        # Only rename if it doesn't already have a timestamp
        if not png_file.startswith('job_{timestamp}_'):
            new_name = f'job_{timestamp}_{{png_file}}'
            try:
                os.rename(png_file, new_name)
                print(f"Renamed {{png_file}} -> {{new_name}}")
            except Exception as e:
                print(f"Error renaming {{png_file}}: {{e}}")

# Close any remaining matplotlib figures
try:
    import matplotlib.pyplot as plt
    plt.close('all')
except:
    pass

# Calculate total execution time
end_time = time.perf_counter()
execution_time = end_time - start_time

print("\\n" + "="*50)
print(f"TOTAL EXECUTION TIME: {{execution_time:.6f}} seconds")
print("✅ Data analysis completed successfully")
print("="*50)
"""
    return wrapped_code

def indent_code(code, spaces):
    """
    Indent each line of code with the specified number of spaces.
    """
    lines = code.split('\\n')
    indented_lines = []
    
    for line in lines:
        if line.strip():  # If the line has content
            # Preserve original indentation and add specified spaces
            indented_lines.append(' ' * spaces + line)
        else:
            # Keep empty lines
            indented_lines.append('')
    
    return '\\n'.join(indented_lines)

def submit_slurm_job(script_path):
    """
    Submit a job to SLURM and return the job ID.
    """
    result = subprocess.run(["sbatch", script_path], capture_output=True, text=True)
    if result.returncode == 0:
        for line in result.stdout.splitlines():
            if "Submitted batch job" in line:
                return line.split()[-1]
        return result.stdout.strip().split()[-1]
    else:
        raise RuntimeError(f"sbatch failed: {result.stderr}")

def wait_for_job(job_id, timeout=300):
    """
    Wait for a SLURM job to complete, up to the specified timeout.
    """
    start = time.time()
    while time.time() - start < timeout:
        status = subprocess.run([
            "squeue", "-j", job_id, "--noheader"
        ], capture_output=True, text=True)
        if not status.stdout.strip():
            return True
        time.sleep(3)
    return False

def extract_execution_time(output):
    """
    Extract execution time from the analysis output.
    """
    pattern = r"TOTAL EXECUTION TIME: (\\d+\\.\\d+) seconds"
    match = re.search(pattern, output)
    if match:
        return float(match.group(1))
    return None

def extract_plots_from_directory(output_dir, timestamp):
    """
    Extract plot files from the output directory for a specific job timestamp.
    """
    import glob
    import base64
    
    plots = []
    output_path = Path(output_dir)
    
    # Look for PNG files with the specific job timestamp
    pattern = f"job_{timestamp}_*.png"
    png_files = list(output_path.glob(pattern))
    print(f"DEBUG: Looking for plots with pattern: {pattern}")
    print(f"DEBUG: Found PNG files: {[f.name for f in png_files]}")
    
    for png_file in png_files:
        try:
            with open(png_file, 'rb') as f:
                plot_data = base64.b64encode(f.read()).decode()
                plots.append(plot_data)
                print(f"DEBUG: Successfully encoded plot: {png_file.name}")
        except Exception as e:
            print(f"DEBUG: Error reading plot {png_file.name}: {e}")
    
    # If no timestamp-specific plots found, check for any recent PNG files as fallback
    if not plots:
        print("DEBUG: No timestamp-specific plots found, checking for any PNG files...")
        all_png_files = list(output_path.glob("*.png"))
        print(f"DEBUG: All PNG files in directory: {[f.name for f in all_png_files]}")
    
    print(f"DEBUG: Total plots extracted from directory: {len(plots)}")
    return plots

def cleanup_old_plots(output_dir, keep_recent=5):
    """
    Clean up old PNG files to prevent confusion, keeping only the most recent ones.
    """
    try:
        output_path = Path(output_dir)
        
        # Get all PNG files sorted by modification time (newest first)
        png_files = list(output_path.glob("*.png"))
        png_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        
        # Remove older files, keeping only the most recent ones
        files_to_remove = png_files[keep_recent:]
        for old_file in files_to_remove:
            try:
                old_file.unlink()
                print(f"Cleaned up old plot file: {old_file.name}")
            except Exception as e:
                print(f"Warning: Could not remove old plot file {old_file.name}: {e}")
        
        if files_to_remove:
            print(f"Cleaned up {len(files_to_remove)} old plot files")
        
    except Exception as e:
        print(f"Warning: Error during plot cleanup: {e}")

def check_job_success(output):
    """
    Check if the job completed successfully.
    """
    return "✅" in output and "completed successfully" in output

def run_data_analysis(code, dataset_path, output_dir):
    """
    Run data analysis code using SLURM and return the results.
    """
    # Create output directory if it doesn't exist
    os.makedirs(output_dir, exist_ok=True)
    
    # Generate unique timestamp for this run
    timestamp = int(time.time())
    
    # Clean up old PNG files to prevent confusion (keep only recent ones)
    cleanup_old_plots(output_dir, keep_recent=5)
    
    # Define file paths
    py_file = Path(output_dir) / f"analysis_{timestamp}.py"
    sh_file = Path(output_dir) / f"analysis_{timestamp}.sh"
    out_file = Path(output_dir) / f"analysis_{timestamp}.out"
    err_file = Path(output_dir) / f"analysis_{timestamp}.err"
    
    # Wrap the code
    wrapped_code = wrap_data_analysis_code(code, dataset_path, timestamp)
    
    # Write Python file
    with open(py_file, 'w') as f:
        f.write(wrapped_code)
    
    # Create SLURM script
    slurm_script = f"""#!/bin/bash
#SBATCH -N 1
#SBATCH -c 4
#SBATCH -t 0-00:10:00
#SBATCH -p general
#SBATCH -q public
#SBATCH -G 1
#SBATCH -o {out_file}
#SBATCH -e {err_file}
#SBATCH --export=NONE

module load mamba/latest
CUDA_MODULES=$(module avail cuda 2>&1 | grep -E "cuda-[0-9]+\\.[0-9]+\\.[0-9]+-gcc" | grep -v "ont-guppy" | sort -V)
if [ -z "$CUDA_MODULES" ]; then echo "No CUDA modules found!"; exit 1; fi
LATEST_CUDA=$(echo "$CUDA_MODULES" | tail -1 | awk '{{print $1}}')
module load $LATEST_CUDA
source activate rapids25.02
cd {output_dir}
python {py_file.name}
"""
    
    with open(sh_file, 'w') as f:
        f.write(slurm_script)
    
    # Make shell script executable
    os.chmod(sh_file, 0o755)
    
    try:
        # Submit job
        job_id = submit_slurm_job(str(sh_file))
        print(f"Submitted job {job_id}")
        
        # Wait for completion
        if wait_for_job(job_id, timeout=600):  # 10 minute timeout
            # Read output
            if out_file.exists():
                with open(out_file, 'r') as f:
                    output = f.read()
            else:
                output = "No output file found."
            
            # Read error
            if err_file.exists():
                with open(err_file, 'r') as f:
                    error = f.read()
            else:
                error = ""
            
            # Extract results
            execution_time = extract_execution_time(output)
            plots = extract_plots_from_directory(output_dir, timestamp)
            success = check_job_success(output)
            
            return {
                "success": success,
                "output": output,
                "error": error,
                "execution_time": execution_time,
                "plots": plots,
                "job_id": job_id
            }
        else:
            return {
                "success": False,
                "output": "Job timed out",
                "error": "Job execution exceeded 10 minute timeout",
                "execution_time": None,
                "plots": [],
                "job_id": job_id
            }
    
    except Exception as e:
        return {
            "success": False,
            "output": "",
            "error": str(e),
            "execution_time": None,
            "plots": [],
            "job_id": None
        }
